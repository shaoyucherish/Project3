---
title: "Project 3"
author: "Shaoyu Wang"
date: "2022-11-09"
output: 
  github_document: default
  html_document:
    code_folding: hide
params:
    columnName: ""
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)
```

# Required Packages

The following packages are required for this project:
```{r}
# Load libraries
library(readr)
library(tidyverse)
library(dplyr)
library(caret)
library(ggplot2)
```

# Introduction

This [online News Popularity Data Set](https://archive.ics.uci.edu/ml/datasets/Online+News+Popularity) summarizes a heterogeneous set of features about articles published by Mashable in a period of two years.


# Data

Use a relative path to import the data and subset the data to work on the data channel of interest.

```{r}
#Read in the data file
newsData <- read_csv("OnlineNewsPopularity.csv",show_col_types = FALSE)
#Choose the data channel of interest
if (params$columnName != "") {
  paramColumnNameType <- params$columnName
} else {
  paramColumnNameType <- "tech"
}
columnName <- paste("data_channel_is_", paramColumnNameType, sep = "")
#Merge the weekdays columns channels as one single column.
news <- newsData %>% 
  filter(.data[[columnName]] == 1) %>% 
  select(url, starts_with("weekday_is_")) %>% 
  pivot_longer(-url) %>% 
  filter(value != 0) %>% 
  mutate(publish_weekday = substr(name, 12, 20)) %>% 
  left_join(newsData, by = "url") %>% 
#Remove non predictive variables
  select(-c(url, name, value, timedelta, starts_with("data_channel_is_"), starts_with("weekday_is_")))
news$publish_weekday <- as.factor(news$publish_weekday)
news
```

Split the data into a training set and a test set.
```{r}
set.seed(111)
trainIndex <- createDataPartition(news$shares, p = 0.7, list = FALSE)
newsTrain <- news[trainIndex,]
newsTest <- news[-trainIndex,]
newsTrain
```

# Summarizations

Some basic summary statistics and plots about the training data.
```{r}
summary(newsTrain)
```

```{r}
#Numerical summaries
newsTrain %>% 
  summarise(mean = round(mean(shares), 0), sd = round(sd(shares), 0), median = round(median(shares), 0), IQR = round(IQR(shares), 0))
newsTrain %>% 
  group_by(publish_weekday) %>% 
  summarise(mean = round(mean(shares), 0), sd = round(sd(shares), 0), median = round(median(shares), 0), IQR = round(IQR(shares), 0))
newsTrain %>% 
  group_by(num_imgs) %>% 
  summarise(mean = round(mean(shares), 0), sd = round(sd(shares), 0), median = round(median(shares), 0), IQR = round(IQR(shares), 0))
newsTrain %>% 
  group_by(num_videos) %>% 
  summarise(mean = round(mean(shares), 0), sd = round(sd(shares), 0), median = round(median(shares), 0), IQR = round(IQR(shares), 0))
newsTrain %>% 
  group_by(num_keywords) %>% 
  summarise(mean = round(mean(shares), 0), sd = round(sd(shares), 0), median = round(median(shares), 0), IQR = round(IQR(shares), 0))
```

```{r}
#Contingency tables
table(newsTrain$publish_weekday)
```

```{r}
g <- ggplot(newsTrain, aes(x = n_tokens_title))
g + geom_histogram(fill = "lightblue", binwidth = 1) + labs()
```
```{r}
g <- ggplot(newsTrain, aes(x = n_tokens_content))
g + geom_histogram(fill = "lightblue") + labs()
```

```{r}
g <- ggplot(newsTrain, aes(x = global_subjectivity))
g + geom_histogram(fill = "lightblue") + labs()
```

```{r}
g <- ggplot(newsTrain, aes(x = global_sentiment_polarity))
g + geom_histogram(fill = "lightblue") + labs()
```

```{r}
g <- ggplot(newsTrain, aes(x = rate_positive_words, y = shares))
g + geom_point() + labs()
```

```{r}
g <- ggplot(newsTrain, aes(x = average_token_length, y = shares))
g + geom_point() + labs()
```



















