---
title: "Project 3"
author: "Shaoyu Wang, Aniket Walimbe"
date: "2022-11-14"
output: github_document
params: 
  channel: ""
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)
```

```{r, include=FALSE, eval=FALSE}
rmarkdown::render("project3.Rmd", 
                  output_format = "github_document",
                  output_file = "README.md",
                  output_options = list(toc=TRUE, toc_depth=1, toc_float=TRUE))
```

# Introduction

This [online News Popularity Data Set](https://archive.ics.uci.edu/ml/datasets/Online+News+Popularity) summarizes a heterogeneous set of features about articles published by Mashable in a period of two years.

# Required Packages

First, we will load the required packages:

```{r}
# Load libraries
library(readr)
library(tidyverse)
library(dplyr)
library(caret)
library(leaps)
library(ggplot2)
library(corrplot)
library(GGally)
library(randomForest)
```

# Data

Use a relative path to import the data and subset the data to work on the data channel of interest.

```{r}
#Read in the data file
newsData <- read_csv("OnlineNewsPopularity.csv",show_col_types = FALSE)
#Choose the data channel of interest
if (params$channel != "") {
  paramChannelName <- params$channel
} else {
  paramChannelName <- "lifestyle"
}
channel <- paste("data_channel_is_", paramChannelName, sep = "")
#Merge the weekdays columns channels as one single column.
news <- newsData %>% 
  filter(.data[[channel]] == 1) %>% 
  select(url, starts_with("weekday_is_")) %>% 
  pivot_longer(-url) %>% 
  filter(value != 0) %>% 
  mutate(publish_weekday = substr(name, 12, 20)) %>% 
  left_join(newsData, by = "url") %>% 
#Remove non predictive variables
  select(-c(url, name, value, timedelta, starts_with("data_channel_is_"), starts_with("weekday_is_")))
news$publish_weekday <- as.factor(news$publish_weekday)
news
```

Split the data into a training set and a test set.
```{r}
set.seed(111)
trainIndex <- createDataPartition(news$shares, p = 0.7, list = FALSE)
newsTrain <- news[trainIndex,]
newsTest <- news[-trainIndex,]
newsTrain
```

# Summarizations

Some basic summary statistics and plots about the training data.
```{r}
#summary for training data
summary(newsTrain)
```

```{r}
#numerical summary for our Y variable shares
summary(newsTrain$shares)
newsTrain %>% 
  summarise(mean = round(mean(shares), 0), sd = round(sd(shares), 0), 
            median = round(median(shares), 0), IQR = round(IQR(shares), 0))
```

```{r}
#numerical summaries on subgroups
newsTrain %>% 
  group_by(publish_weekday) %>% 
  summarise(mean = round(mean(shares), 0), sd = round(sd(shares), 0), 
            median = round(median(shares), 0), IQR = round(IQR(shares), 0))
newsTrain %>% 
  group_by(num_imgs) %>% 
  summarise(mean = round(mean(shares), 0), sd = round(sd(shares), 0), 
            median = round(median(shares), 0), IQR = round(IQR(shares), 0))
newsTrain %>% 
  group_by(num_videos) %>% 
  summarise(mean = round(mean(shares), 0), sd = round(sd(shares), 0), 
            median = round(median(shares), 0), IQR = round(IQR(shares), 0))
newsTrain %>% 
  group_by(num_keywords) %>% 
  summarise(mean = round(mean(shares), 0), sd = round(sd(shares), 0), 
            median = round(median(shares), 0), IQR = round(IQR(shares), 0))
```

# Contingency tables
Contingency tables : Here, the title subjectivity is divided into 3 categories : high, medium and low based on the values. If the value is greater than 0.8, it is high, greater than 0.4 and less than 0.8 is medium and remaining is low. The contingency table is then shown below. 

```{r}
newsTrain$subject_activity_type <- ifelse(newsTrain$title_subjectivity >= 0.8, "High", 
                                          ifelse(newsTrain$title_subjectivity >= 0.4, "Medium",
                                                 ifelse(airquality$Wind >= 0, "Low", "None")))
table(newsTrain$subject_activity_type)
```


```{r}
table(newsTrain$publish_weekday)
```

```{r}
g <- ggplot(newsTrain, aes(x = n_tokens_title))
g + geom_histogram(fill = "lightblue", binwidth = 1) + 
  labs()
```

```{r}
g <- ggplot(newsTrain, aes(x = n_tokens_content))
g + geom_histogram(fill = "lightblue") + 
  labs()
```

```{r}
g <- ggplot(newsTrain, aes(x = global_subjectivity))
g + geom_histogram(fill = "lightblue") + 
  labs()
```

```{r}
g <- ggplot(newsTrain, aes(x = global_sentiment_polarity))
g + geom_histogram(fill = "lightblue") + 
  labs()
```

```{r}
g <- ggplot(newsTrain, aes(x = rate_positive_words, y = shares))
g + geom_point() + 
  labs()
```

```{r}
g <- ggplot(newsTrain, aes(x = average_token_length, y = shares))
g + geom_point() + 
  labs()
```

Plot between title subjectivity and number of shares: We can inspect the trend of the shares as a function of title subjectivity. 
```{r}
g <- ggplot(data = newsTrain, aes(x = title_subjectivity, y = shares))
g + geom_point() + 
  labs(x = "Title subjectivity" , y = "Number of shares", title = "Scatter Plot : Title Subjectivity Vs Number of Shares") 

```

Plot between number of shares and article published day: This plot shows the number of shares an article has based on the day it has been published.
```{r}
newsTrainday <- newsTrain %>%
  select(publish_weekday, shares) %>%
  group_by(publish_weekday) %>% 
  summarise(total_shares=sum(shares))

g <- ggplot(data = newsTrainday, aes(x=publish_weekday, y=total_shares))
g + geom_col(fill = "lightblue")+
  labs(title = " Shares for articles published based on weekdays")
```

Plot between number of images and number of shares: 
```{r}
g <- ggplot(data = newsTrain, aes(x = num_imgs, y = shares))
g + geom_point() +
  labs(x = "Number of Images" , y = "Number of shares", title = "Scatter Plot : Number of Images Vs Number of Shares") 
```

Plotting the correlation between numeric variables.
```{r}
correlation <- cor(newsTrain %>% select(-c(publish_weekday, subject_activity_type)), method = "spearman")
corrplot(correlation, type = "upper", tl.pos = "lt", tl.col = "black", tl.cex = 0.5, mar = c(2, 0, 1, 0)) 
corrplot(correlation, type = "lower", add = TRUE, diag = FALSE, tl.pos = "n", number.cex = 0.5)
```

Select predictors: publish_weekday, n_tokens_title, n_tokens_content, num_self_hrefs, num_videos, average_token_length, num_keywords, kw_avg_avg, self_reference_avg_sharess, LDA_04, global_subjectivity, global_sentiment_polarity, avg_positive_polarity, avg_negative_polarity, title_subjectivity, shares.

```{r}
set.seed(111)
Train <- newsTrain %>% 
  select(publish_weekday, n_tokens_title, n_tokens_content, num_self_hrefs, num_videos, average_token_length, num_keywords, kw_avg_avg, self_reference_avg_sharess, LDA_04, global_subjectivity, global_sentiment_polarity, avg_positive_polarity, avg_negative_polarity, title_subjectivity, shares)
Test <- newsTest %>% 
  select(publish_weekday, n_tokens_title, n_tokens_content, num_self_hrefs, num_videos, average_token_length, num_keywords, kw_avg_avg, self_reference_avg_sharess, LDA_04, global_subjectivity, global_sentiment_polarity, avg_positive_polarity, avg_negative_polarity, title_subjectivity, shares)
Train
```

# Model

## Linear Regression Model

```{r}
#forward stepwise
set.seed(111)
fwFit <- train(shares ~ ., data = Train,
                   method = "leapForward",
                   preProcess = c("center", "scale"))
fwFit
#summary(fwFit)
```

```{r}
#backward stepwise
set.seed(111)
bwFit <- train(shares ~ ., data = Train,
                   method = "leapBackward",
                   preProcess = c("center", "scale"))
bwFit
#summary(bwFit)
```
```{r}
#fit a linear regression model with 2 predictors: num_videos, kw_avg_avg
set.seed(111)
lrFit_2 <- train(shares ~ num_videos + kw_avg_avg, data = Train,
               method = "lm",
               trControl = trainControl(method = "cv", number = 5))
lrFit_2
```

```{r}
#fit a linear regression model with 3 predictors: n_tokens_content, num_videos, kw_avg_avg
set.seed(111)
lrFit_3 <- train(shares ~ n_tokens_content + num_videos + kw_avg_avg, data = Train,
               method = "lm",
               trControl = trainControl(method = "cv", number = 5))
lrFit_3
```

```{r}
#fit a linear regression model with all predictors
set.seed(111)
lrFit <- train(shares ~ ., data = Train,
               method = "lm",
               trControl = trainControl(method = "cv", number = 5))
lrFit
```

## Random Forest Model
```{r}
set.seed(111)
randomFit <- train(shares ~ ., 
                   data = Train, 
                   method = "rf",
                   preProcess = c("center","scale"),
                   trControl = trainControl(method = "cv", number = 5),
                   tuneGrid = data.frame(mtry = ncol(Train)/3))
randomFit
```

## Boosted Tree Model
```{r}
set.seed(111)
boostedFit <- train(shares ~ ., 
                    data = Train, 
                    method = "gbm", 
                    preProcess = c("center", "scale"),
                    trControl = trainControl(method = "cv", number = 5),
                    tuneGrid = expand.grid(n.trees = c(25,50,100,150,200), 
                                           interaction.depth = c(1,2,3,4), 
                                           shrinkage = 0.1, 
                                           n.minobsinnode = 10),
                    verbose = FALSE)
boostedFit
```

## Comparison

All the models are compared by RMSE on the test set

```{r}
#pred_Fit2 <- predict(lrFit_2, newdata = Test)
fit2_mod <- postResample(predict(lrFit_2, newdata = Test), obs = Test$shares)
#pred_Fit3 <- predict(lrFit_3, newdata = Test)
fit3_mod <- postResample(predict(lrFit_3, newdata = Test), obs = Test$shares)
#fit a linear regression model
#pred_lrFit <- predict(lrFit, newdata = Test)
lr_mod <- postResample(predict(lrFit, newdata = Test), obs = Test$shares)
#random forest
#pred_randomFit <- predict(randomFit, newdata = Test)
random_mod <- postResample(predict(randomFit, newdata = Test), obs = Test$shares)
#boosted tree
#pred_boostedFit <- predict(boostedFit, newdata = Test)
boosted_mod <- postResample(predict(boostedFit, newdata = Test), obs = Test$shares)
#compare all models
comparison <- tibble(model = c("LR with 2 predictors",
                               "LR with 3 predictors",
                               "LR with all predictors",
                               "Random Forest",
                               "Boosted Tree"), 
                     RMSE = c(fit2_mod[1],
                              fit3_mod[1],
                              lr_mod[1],
                              random_mod[1],
                              boosted_mod[1]))
comparison
```












