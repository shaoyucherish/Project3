#random forest
random_mod <- postResample(predict(randomFit, newdata = Test), obs = Test$shares)
#boosted tree
boosted_mod <- postResample(predict(boostedFit, newdata = Test), obs = Test$shares)
#compare all models
tibble(model = c("Forward",
"Backward",
"LR with all predictors",
"Random Forest",
"Boosted Tree"),
RMSE = c(fw_mod[1],
bw_mod[1],
lr_mod[1],
random_mod[1],
boosted_mod[1]))
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)
# Load libraries
library(readr)
library(tidyverse)
library(dplyr)
library(caret)
library(leaps)
library(ggplot2)
library(corrplot)
library(GGally)
library(randomForest)
#Read in the data file
newsData <- read_csv("OnlineNewsPopularity.csv",show_col_types = FALSE)
#Choose the data channel of interest
if (params$channel != "") {
paramChannelName <- params$channel
} else {
paramChannelName <- "lifestyle"
}
channel <- paste("data_channel_is_", paramChannelName, sep = "")
#Merge the weekday columns as one single column.
news <- newsData %>%
filter(.data[[channel]] == 1) %>%
select(url, starts_with("weekday_is_")) %>%
pivot_longer(-url) %>%
filter(value != 0) %>%
mutate(publish_weekday = substr(name, 12, 20)) %>%
left_join(newsData, by = "url") %>%
#Remove non predictive variables
select(-c(url, name, value, timedelta, starts_with("data_channel_is_"), starts_with("weekday_is_")))
news$publish_weekday <- as.factor(news$publish_weekday)
news
set.seed(111)
trainIndex <- createDataPartition(news$shares, p = 0.7, list = FALSE)
newsTrain <- news[trainIndex,]
newsTest <- news[-trainIndex,]
#newsTrain
summary(newsTrain)
#numerical summary for the variable shares
newsTrain %>%
summarise(mean = round(mean(shares), 0), sd = round(sd(shares), 0),
median = round(median(shares), 0), IQR = round(IQR(shares), 0))
#numerical summaries on subgroups
newsTrain %>%
group_by(publish_weekday) %>%
summarise(mean = round(mean(shares), 0), sd = round(sd(shares), 0),
median = round(median(shares), 0), IQR = round(IQR(shares), 0))
newsTrain %>%
group_by(num_imgs) %>%
summarise(mean = round(mean(shares), 0), sd = round(sd(shares), 0),
median = round(median(shares), 0), IQR = round(IQR(shares), 0))
newsTrain %>%
group_by(num_keywords) %>%
summarise(mean = round(mean(shares), 0), sd = round(sd(shares), 0),
median = round(median(shares), 0), IQR = round(IQR(shares), 0))
newsTrain$subject_activity_type <- ifelse(newsTrain$title_subjectivity >= 0.8, "High",
ifelse(newsTrain$title_subjectivity >= 0.4, "Medium",
ifelse(airquality$Wind >= 0, "Low")))
table(newsTrain$subject_activity_type)
newsTrainsub <- newsTrain %>% select(-c(publish_weekday, subject_activity_type))
correlation <- cor(newsTrainsub, method = "spearman")
corrplot(correlation, type = "upper", tl.pos = "lt", tl.col = "black", tl.cex = 0.5, mar = c(2, 0, 1, 0))
corrplot(correlation, type = "lower", add = TRUE, diag = FALSE, tl.pos = "n", number.cex = 0.5)
newsTrainday <- newsTrain %>%
select(publish_weekday, shares) %>%
group_by(publish_weekday) %>%
summarise(total_shares=sum(shares))
g <- ggplot(data = newsTrainday, aes(x=publish_weekday, y=total_shares))
g + geom_col(fill = "lightblue")+
labs(title = " Shares for articles published based on weekdays")
g <- ggplot(newsTrain, aes(x = n_tokens_title))
g + geom_histogram(fill = "lightblue", binwidth = 1) +
labs(x = "Number of words in the title",
title = "Histogram: Number of words in the title")
g <- ggplot(newsTrain, aes(x = n_tokens_content))
g + geom_histogram(fill = "lightblue") +
labs(x = "Number of words in the content",
title = "Histogram: Number of words in the content")
g <- ggplot(newsTrain, aes(x = global_subjectivity))
g + geom_histogram(fill = "lightblue") +
labs(x = "Text subjectivity",
title = "Histogram: Text subjectivity")
g <- ggplot(newsTrain, aes(x = global_sentiment_polarity))
g + geom_histogram(fill = "lightblue") +
labs(x = "Text sentiment polarity",
title = "Histogram: Text sentiment polarity")
g <- ggplot(data = newsTrain, aes(x = num_imgs, y = shares))
g + geom_point() +
labs(x = "Number of images" , y = "Number of shares",
title = "Scatter Plot: Number of images VS Number of shares")
g <- ggplot(newsTrain, aes(x = average_token_length, y = shares))
g + geom_point() +
labs(x = "Average token length" , y = "Number of shares",
title = "Scatter Plot: Average token length VS Number of shares")
g <- ggplot(data = newsTrain, aes(x = title_subjectivity, y = shares))
g + geom_point() +
labs(x = "Title subjectivity" , y = "Number of shares",
title = "Scatter Plot: Title subjectivity VS Number of shares")
set.seed(111)
Train <- newsTrain %>%
select(publish_weekday, n_tokens_title, n_tokens_content, num_self_hrefs, num_imgs, average_token_length, num_keywords, kw_avg_avg, self_reference_avg_sharess, LDA_04, global_subjectivity, global_sentiment_polarity, avg_positive_polarity, avg_negative_polarity, title_subjectivity, shares)
Test <- newsTest %>%
select(publish_weekday, n_tokens_title, n_tokens_content, num_self_hrefs, num_imgs, average_token_length, num_keywords, kw_avg_avg, self_reference_avg_sharess, LDA_04, global_subjectivity, global_sentiment_polarity, avg_positive_polarity, avg_negative_polarity, title_subjectivity, shares)
#Train
#forward stepwise
set.seed(111)
fwFit <- train(shares ~ ., data = Train,
method = "leapForward",
preProcess = c("center", "scale"))
fwFit
#summary(fwFit)
#backward stepwise
set.seed(111)
bwFit <- train(shares ~ ., data = Train,
method = "leapBackward",
preProcess = c("center", "scale"))
bwFit
#summary(bwFit)
#fit a linear regression model with all predictors
set.seed(111)
lrFit <- train(shares ~ ., data = Train,
method = "lm",
trControl = trainControl(method = "cv", number = 5))
lrFit
set.seed(111)
randomFit <- train(shares ~ .,
data = Train,
method = "rf",
preProcess = c("center","scale"),
trControl = trainControl(method = "cv", number = 5),
tuneGrid = data.frame(mtry = ncol(Train)/3))
randomFit
set.seed(111)
boostedFit <- train(shares ~ .,
data = Train,
method = "gbm",
preProcess = c("center", "scale"),
trControl = trainControl(method = "cv", number = 5),
tuneGrid = expand.grid(n.trees = c(25,50,100,150,200),
interaction.depth = c(1,2,3,4),
shrinkage = 0.1,
n.minobsinnode = 10),
verbose = FALSE)
boostedFit
#fit a linear regression model
fw_mod <- postResample(predict(fwFit, newdata = Test), obs = Test$shares)
bw_mod <- postResample(predict(bwFit, newdata = Test), obs = Test$shares)
lr_mod <- postResample(predict(lrFit, newdata = Test), obs = Test$shares)
#random forest
random_mod <- postResample(predict(randomFit, newdata = Test), obs = Test$shares)
#boosted tree
boosted_mod <- postResample(predict(boostedFit, newdata = Test), obs = Test$shares)
#compare all models
tibble(model = c("Forward",
"Backward",
"LR with all predictors",
"Random Forest",
"Boosted Tree"),
RMSE = c(fw_mod[1],
bw_mod[1],
lr_mod[1],
random_mod[1],
boosted_mod[1]))
rmarkdown::render("project3.Rmd",
output_format = "github_document",
output_file = "README.md",
output_options = list(toc=TRUE, toc_depth=1, toc_float=TRUE))
rmarkdown::render("project3.Rmd",
output_format = "github_document",
output_file = "README.md",
output_options = list(toc=TRUE, toc_depth=1, toc_float=TRUE))
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)
# Load libraries
library(readr)
library(tidyverse)
library(dplyr)
library(caret)
library(leaps)
library(ggplot2)
library(corrplot)
library(GGally)
library(randomForest)
#Read in the data file
newsData <- read_csv("OnlineNewsPopularity.csv",show_col_types = FALSE)
#Choose the data channel of interest
if (params$channel != "") {
paramChannelName <- params$channel
} else {
paramChannelName <- "lifestyle"
}
channel <- paste("data_channel_is_", paramChannelName, sep = "")
#Merge the weekday columns as one single column.
news <- newsData %>%
filter(.data[[channel]] == 1) %>%
select(url, starts_with("weekday_is_")) %>%
pivot_longer(-url) %>%
filter(value != 0) %>%
mutate(publish_weekday = substr(name, 12, 20)) %>%
left_join(newsData, by = "url") %>%
#Remove non predictive variables
select(-c(url, name, value, timedelta, starts_with("data_channel_is_"), starts_with("weekday_is_")))
news$publish_weekday <- as.factor(news$publish_weekday)
news
set.seed(111)
trainIndex <- createDataPartition(news$shares, p = 0.7, list = FALSE)
newsTrain <- news[trainIndex,]
newsTest <- news[-trainIndex,]
#newsTrain
summary(newsTrain)
#numerical summary for the variable shares
newsTrain %>%
summarise(mean = round(mean(shares), 0), sd = round(sd(shares), 0),
median = round(median(shares), 0), IQR = round(IQR(shares), 0))
#numerical summaries on subgroups
newsTrain %>%
group_by(publish_weekday) %>%
summarise(mean = round(mean(shares), 0), sd = round(sd(shares), 0),
median = round(median(shares), 0), IQR = round(IQR(shares), 0))
newsTrain %>%
group_by(num_imgs) %>%
summarise(mean = round(mean(shares), 0), sd = round(sd(shares), 0),
median = round(median(shares), 0), IQR = round(IQR(shares), 0))
newsTrain %>%
group_by(num_keywords) %>%
summarise(mean = round(mean(shares), 0), sd = round(sd(shares), 0),
median = round(median(shares), 0), IQR = round(IQR(shares), 0))
newsTrain$subject_activity_type <- ifelse(newsTrain$title_subjectivity >= 0.8, "High",
ifelse(newsTrain$title_subjectivity >= 0.4, "Medium",
ifelse(airquality$Wind >= 0, "Low")))
table(newsTrain$subject_activity_type)
newsTrainsub <- newsTrain %>% select(-c(publish_weekday, subject_activity_type))
correlation <- cor(newsTrainsub, method = "spearman")
corrplot(correlation, type = "upper", tl.pos = "lt", tl.col = "black", tl.cex = 0.5, mar = c(2, 0, 1, 0))
corrplot(correlation, type = "lower", add = TRUE, diag = FALSE, tl.pos = "n", number.cex = 0.5)
newsTrainday <- newsTrain %>%
select(publish_weekday, shares) %>%
group_by(publish_weekday) %>%
summarise(total_shares=sum(shares))
g <- ggplot(data = newsTrainday, aes(x=publish_weekday, y=total_shares))
g + geom_col(fill = "lightblue")+
labs(title = " Shares for articles published based on weekdays")
g <- ggplot(newsTrain, aes(x = n_tokens_title))
g + geom_histogram(fill = "lightblue", binwidth = 1) +
labs(x = "Number of words in the title",
title = "Histogram: Number of words in the title")
g <- ggplot(newsTrain, aes(x = n_tokens_content))
g + geom_histogram(fill = "lightblue") +
labs(x = "Number of words in the content",
title = "Histogram: Number of words in the content")
g <- ggplot(newsTrain, aes(x = global_subjectivity))
g + geom_histogram(fill = "lightblue") +
labs(x = "Text subjectivity",
title = "Histogram: Text subjectivity")
g <- ggplot(newsTrain, aes(x = global_sentiment_polarity))
g + geom_histogram(fill = "lightblue") +
labs(x = "Text sentiment polarity",
title = "Histogram: Text sentiment polarity")
g <- ggplot(data = newsTrain, aes(x = num_imgs, y = shares))
g + geom_point() +
labs(x = "Number of images" , y = "Number of shares",
title = "Scatter Plot: Number of images VS Number of shares")
g <- ggplot(newsTrain, aes(x = average_token_length, y = shares))
g + geom_point() +
labs(x = "Average token length" , y = "Number of shares",
title = "Scatter Plot: Average token length VS Number of shares")
g <- ggplot(data = newsTrain, aes(x = title_subjectivity, y = shares))
g + geom_point() +
labs(x = "Title subjectivity" , y = "Number of shares",
title = "Scatter Plot: Title subjectivity VS Number of shares")
set.seed(111)
Train <- newsTrain %>%
select(publish_weekday, n_tokens_title, n_tokens_content, num_self_hrefs, num_imgs, average_token_length, num_keywords, kw_avg_avg, self_reference_avg_sharess, LDA_04, global_subjectivity, global_sentiment_polarity, avg_positive_polarity, avg_negative_polarity, title_subjectivity, shares)
Test <- newsTest %>%
select(publish_weekday, n_tokens_title, n_tokens_content, num_self_hrefs, num_imgs, average_token_length, num_keywords, kw_avg_avg, self_reference_avg_sharess, LDA_04, global_subjectivity, global_sentiment_polarity, avg_positive_polarity, avg_negative_polarity, title_subjectivity, shares)
#Train
#forward stepwise
set.seed(111)
fwFit <- train(shares ~ ., data = Train,
method = "leapForward",
preProcess = c("center", "scale"))
fwFit
#summary(fwFit)
#backward stepwise
set.seed(111)
bwFit <- train(shares ~ ., data = Train,
method = "leapBackward",
preProcess = c("center", "scale"))
bwFit
#summary(bwFit)
#fit a linear regression model with all predictors
set.seed(111)
lrFit <- train(shares ~ ., data = Train,
method = "lm",
trControl = trainControl(method = "cv", number = 5))
lrFit
set.seed(111)
randomFit <- train(shares ~ .,
data = Train,
method = "rf",
preProcess = c("center","scale"),
trControl = trainControl(method = "cv", number = 5),
tuneGrid = data.frame(mtry = ncol(Train)/3))
randomFit
set.seed(111)
boostedFit <- train(shares ~ .,
data = Train,
method = "gbm",
preProcess = c("center", "scale"),
trControl = trainControl(method = "cv", number = 5),
tuneGrid = expand.grid(n.trees = c(25,50,100,150,200),
interaction.depth = c(1,2,3,4),
shrinkage = 0.1,
n.minobsinnode = 10),
verbose = FALSE)
boostedFit
#fit a linear regression model
fw_mod <- postResample(predict(fwFit, newdata = Test), obs = Test$shares)
bw_mod <- postResample(predict(bwFit, newdata = Test), obs = Test$shares)
lr_mod <- postResample(predict(lrFit, newdata = Test), obs = Test$shares)
#random forest
random_mod <- postResample(predict(randomFit, newdata = Test), obs = Test$shares)
#boosted tree
boosted_mod <- postResample(predict(boostedFit, newdata = Test), obs = Test$shares)
#compare all models
tibble(model = c("Forward",
"Backward",
"LR with all predictors",
"Random Forest",
"Boosted Tree"),
RMSE = c(fw_mod[1],
bw_mod[1],
lr_mod[1],
random_mod[1],
boosted_mod[1]))
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)
# Load libraries
library(readr)
library(tidyverse)
library(dplyr)
library(caret)
library(leaps)
library(ggplot2)
library(corrplot)
library(GGally)
library(randomForest)
#Read in the data file
newsData <- read_csv("OnlineNewsPopularity.csv",show_col_types = FALSE)
#Choose the data channel of interest
if (params$channel != "") {
paramChannelName <- params$channel
} else {
paramChannelName <- "lifestyle"
}
channel <- paste("data_channel_is_", paramChannelName, sep = "")
#Merge the weekday columns as one single column.
news <- newsData %>%
filter(.data[[channel]] == 1) %>%
select(url, starts_with("weekday_is_")) %>%
pivot_longer(-url) %>%
filter(value != 0) %>%
mutate(publish_weekday = substr(name, 12, 20)) %>%
left_join(newsData, by = "url") %>%
#Remove non predictive variables
select(-c(url, name, value, timedelta, starts_with("data_channel_is_"), starts_with("weekday_is_")))
news$publish_weekday <- as.factor(news$publish_weekday)
news
set.seed(111)
trainIndex <- createDataPartition(news$shares, p = 0.7, list = FALSE)
newsTrain <- news[trainIndex,]
newsTest <- news[-trainIndex,]
#newsTrain
summary(newsTrain)
#numerical summary for the variable shares
newsTrain %>%
summarise(mean = round(mean(shares), 0), sd = round(sd(shares), 0),
median = round(median(shares), 0), IQR = round(IQR(shares), 0))
#numerical summaries on subgroups
newsTrain %>%
group_by(publish_weekday) %>%
summarise(mean = round(mean(shares), 0), sd = round(sd(shares), 0),
median = round(median(shares), 0), IQR = round(IQR(shares), 0))
newsTrain %>%
group_by(num_imgs) %>%
summarise(mean = round(mean(shares), 0), sd = round(sd(shares), 0),
median = round(median(shares), 0), IQR = round(IQR(shares), 0))
newsTrain %>%
group_by(num_keywords) %>%
summarise(mean = round(mean(shares), 0), sd = round(sd(shares), 0),
median = round(median(shares), 0), IQR = round(IQR(shares), 0))
newsTrain$subject_activity_type <- ifelse(newsTrain$title_subjectivity >= 0.8, "High",
ifelse(newsTrain$title_subjectivity >= 0.4, "Medium",
ifelse(airquality$Wind >= 0, "Low")))
table(newsTrain$subject_activity_type)
newsTrainsub <- newsTrain %>% select(-c(publish_weekday, subject_activity_type))
correlation <- cor(newsTrainsub, method = "spearman")
corrplot(correlation, type = "upper", tl.pos = "lt", tl.col = "black", tl.cex = 0.5, mar = c(2, 0, 1, 0))
corrplot(correlation, type = "lower", add = TRUE, diag = FALSE, tl.pos = "n", number.cex = 0.5)
newsTrainday <- newsTrain %>%
select(publish_weekday, shares) %>%
group_by(publish_weekday) %>%
summarise(total_shares=sum(shares))
g <- ggplot(data = newsTrainday, aes(x=publish_weekday, y=total_shares))
g + geom_col(fill = "lightblue")+
labs(title = " Shares for articles published based on weekdays")
g <- ggplot(newsTrain, aes(x = n_tokens_title))
g + geom_histogram(fill = "lightblue", binwidth = 1) +
labs(x = "Number of words in the title",
title = "Histogram: Number of words in the title")
g <- ggplot(newsTrain, aes(x = n_tokens_content))
g + geom_histogram(fill = "lightblue") +
labs(x = "Number of words in the content",
title = "Histogram: Number of words in the content")
g <- ggplot(newsTrain, aes(x = global_subjectivity))
g + geom_histogram(fill = "lightblue") +
labs(x = "Text subjectivity",
title = "Histogram: Text subjectivity")
g <- ggplot(newsTrain, aes(x = global_sentiment_polarity))
g + geom_histogram(fill = "lightblue") +
labs(x = "Text sentiment polarity",
title = "Histogram: Text sentiment polarity")
g <- ggplot(data = newsTrain, aes(x = num_imgs, y = shares))
g + geom_point() +
labs(x = "Number of images" , y = "Number of shares",
title = "Scatter Plot: Number of images VS Number of shares")
g <- ggplot(newsTrain, aes(x = average_token_length, y = shares))
g + geom_point() +
labs(x = "Average token length" , y = "Number of shares",
title = "Scatter Plot: Average token length VS Number of shares")
g <- ggplot(data = newsTrain, aes(x = title_subjectivity, y = shares))
g + geom_point() +
labs(x = "Title subjectivity" , y = "Number of shares",
title = "Scatter Plot: Title subjectivity VS Number of shares")
set.seed(111)
Train <- newsTrain %>%
select(publish_weekday, n_tokens_title, n_tokens_content, num_self_hrefs, num_imgs, average_token_length, num_keywords, kw_avg_avg, self_reference_avg_sharess, LDA_04, global_subjectivity, global_sentiment_polarity, avg_positive_polarity, avg_negative_polarity, title_subjectivity, shares)
Test <- newsTest %>%
select(publish_weekday, n_tokens_title, n_tokens_content, num_self_hrefs, num_imgs, average_token_length, num_keywords, kw_avg_avg, self_reference_avg_sharess, LDA_04, global_subjectivity, global_sentiment_polarity, avg_positive_polarity, avg_negative_polarity, title_subjectivity, shares)
#Train
#forward stepwise
set.seed(111)
fwFit <- train(shares ~ ., data = Train,
method = "leapForward",
preProcess = c("center", "scale"))
#summary(fwFit)
fwFit
#backward stepwise
set.seed(111)
bwFit <- train(shares ~ ., data = Train,
method = "leapBackward",
preProcess = c("center", "scale"))
#summary(bwFit)
bwFit
#fit a linear regression model with all predictors
set.seed(111)
lrFit <- train(shares ~ ., data = Train,
method = "lm",
trControl = trainControl(method = "cv", number = 5))
lrFit
set.seed(111)
randomFit <- train(shares ~ .,
data = Train,
method = "rf",
preProcess = c("center","scale"),
trControl = trainControl(method = "cv", number = 5),
tuneGrid = data.frame(mtry = ncol(Train)/3))
randomFit
set.seed(111)
boostedFit <- train(shares ~ .,
data = Train,
method = "gbm",
preProcess = c("center", "scale"),
trControl = trainControl(method = "cv", number = 5),
tuneGrid = expand.grid(n.trees = c(25,50,100,150,200),
interaction.depth = c(1,2,3,4),
shrinkage = 0.1,
n.minobsinnode = 10),
verbose = FALSE)
boostedFit
#fit a linear regression model
fw_mod <- postResample(predict(fwFit, newdata = Test), obs = Test$shares)
bw_mod <- postResample(predict(bwFit, newdata = Test), obs = Test$shares)
lr_mod <- postResample(predict(lrFit, newdata = Test), obs = Test$shares)
#random forest
random_mod <- postResample(predict(randomFit, newdata = Test), obs = Test$shares)
#boosted tree
boosted_mod <- postResample(predict(boostedFit, newdata = Test), obs = Test$shares)
#compare all models
tibble(model = c("Forward",
"Backward",
"LR with all predictors",
"Random Forest",
"Boosted Tree"),
RMSE = c(fw_mod[1],
bw_mod[1],
lr_mod[1],
random_mod[1],
boosted_mod[1]))
